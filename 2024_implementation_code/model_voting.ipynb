{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "sys.path.append('/root/code')\n",
    "\n",
    "import h5py as h5\n",
    "from definitions import LOG_DIR, WEIGHT_DIR, DATASET_DIR\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from utils.contrastiveLoss import ContrastiveLoss\n",
    "from models.SCNN18 import SCNN18\n",
    "from models.SCNN18Regression import SCNN18Regression\n",
    "# from models.SCNN18_Sigmoid_oneSecond import SCNN18_Sigmoid\n",
    "from models.Complex_SCNN18_Sigmoid import Complex_SCNN18_Sigmoid\n",
    "from models.Complex_SCNN18 import Complex_SCNN18\n",
    "from models.SCNN18_Sigmoid_First4Modified import SCNN18_Sigmoid_First4Modified\n",
    "from models.SCNN18_sigmoid_res_21pts import SCNN18_sigmoid_res_21pts\n",
    "from models.SCNN18_Sigmoid import SCNN18_Sigmoid\n",
    "from models.SCNN18_Sigmoid_threeSecond import SCNN18_Sigmoid_threeSecond\n",
    "from models.SCNN18_Target_Task import SCNN18_Target_Task\n",
    "from models.SCNN18_Sigmoid_Target_Task import SCNN18_Sigmoid_Target_Task\n",
    "from models.SCNN18_random_aug import SCNN18_random_aug\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import utils.dataset as dataset\n",
    "import logging\n",
    "from logging import handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = logging.getLogger('root')\n",
    "\n",
    "def initLog(debug=False):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(levelname)s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M',\n",
    "        handlers=[logging.StreamHandler(), handlers.RotatingFileHandler('SCNN18_0.1second.log', \"w\", 1024 * 1024 * 100, 3, \"utf-8\")]\n",
    "    )\n",
    "    LOG.setLevel(logging.DEBUG if debug else logging.INFO)\n",
    "    tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initLog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, lr):\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'adadelta':\n",
    "        return tf.optimizers.Adadelta() if lr == 0 else tf.optimizers.Adadelta(learning_rate=lr)\n",
    "    elif optimizer == 'adagrad':\n",
    "        return tf.optimizers.Adagrad() if lr == 0 else tf.optimizers.Adagrad(learning_rate=lr)\n",
    "    elif optimizer == 'adam':\n",
    "        return tf.optimizers.Adam() if lr == 0 else tf.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'adamax':\n",
    "        return tf.optimizers.Adamax() if lr == 0 else tf.optimizers.Adamax(learning_rate=lr)\n",
    "    elif optimizer == 'sgd':\n",
    "        return tf.optimizers.SGD() if lr == 0 else tf.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        return tf.optimizers.RMSprop() if lr == 0 else tf.optimizers.RMSprop(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameter\n",
    "lr = 1.0\n",
    "max_epochs = 160\n",
    "batch_size = 100\n",
    "input_height = 32000\n",
    "input_width = 1\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4646, 32000, 1)\n",
      "(4646, 10)\n"
     ]
    }
   ],
   "source": [
    "test_label_range = ['0.5s - 0.6s', '0.6s - 0.7s', '0.7s - 0.8s', '0.8s - 0.9s', '0.9s - 1.0s', \n",
    "                    '1.0s - 1.1s', '1.1s - 1.2s', '1.2s - 1.3s', '1.3s - 1.4s', '1.4s - 1.5s']\n",
    "\n",
    "# test_ds = dataset.load('./SCNN18_0.1second/SCNNR-Jamendo-test.h5')\n",
    "test_data = dataset.get_dataset_without_label('./SCNN18_0.1second/SCNNR-RWC-test_4.h5')\n",
    "test_label = dataset.get_ground_truth('./SCNN18_0.1second/SCNNR-RWC-test_4.h5')\n",
    "test_data = test_data[:]\n",
    "test_label = test_label[:]\n",
    "\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_label[:, 0]))\n",
    "\n",
    "# test_data = dataset.get_dataset_without_label('./SCNN18_0.1second/SCNN-FMA-nogap-test.h5')\n",
    "# test_label = dataset.get_ground_truth('./SCNN18_0.1second/SCNN-FMA-nogap-test.h5')\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_label[:, 9, :]))\n",
    "\n",
    "# dataset_length = [i for i, _ in enumerate(test_ds)][-1] + 1\n",
    "# print(dataset_length)\n",
    "\n",
    "test_dataset = 'SCNNR-RWC-test_4.h5'\n",
    "# test_dataset = 'SCNN-RWC-ignoreGap-test.h5'\n",
    "\n",
    "# test_ds = test_ds.batch(batch_size)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_weights = [\n",
    "    \"2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5\",\n",
    "    \"2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5\",\n",
    "    \"2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5\",\n",
    "    \"2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5\",\n",
    "    \"2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[f'/gpu:{i}' for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_weights(input_shape, nb_classes, weight_file):\n",
    "    with strategy.scope():\n",
    "        model = SCNN18_Sigmoid(input_shape, nb_classes).model()\n",
    "        optimizer = get_optimizer('adadelta', lr)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.load_weights(os.path.join(WEIGHT_DIR, weight_file))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (input_height, input_width)\n",
    "models = [load_model_with_weights(input_shape, nb_classes, weight) for weight in training_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 N 個分類器進行多數決\n",
    "# predictions = [model.predict(test_data) for model in models]\n",
    "# predictions = np.array(predictions)\n",
    "\n",
    "# for i in range(nb_classes):\n",
    "#     predict_true = 0\n",
    "\n",
    "#     for j in range(predictions.shape[1]):\n",
    "#         vocal_num = 0\n",
    "#         non_vocal_num = 0\n",
    "\n",
    "#         for k in range(predictions.shape[0]):\n",
    "#             if(predictions[k, j, i] < 0.5):\n",
    "#                 non_vocal_num += 1\n",
    "#             else:\n",
    "#                 vocal_num += 1\n",
    "            \n",
    "#         if(vocal_num > non_vocal_num and test_label[j, i] == 1):\n",
    "#             predict_true += 1\n",
    "#         elif(vocal_num < non_vocal_num and test_label[j, i] == 0):\n",
    "#             predict_true += 1\n",
    "\n",
    "#     acc = predict_true/predictions.shape[1]\n",
    "\n",
    "#     LOG.info(f'loaded_weight={training_weights}, test_dataset={test_dataset}, second_range={test_label_range[i]}, acc={acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=0.5s - 0.6s, acc=0.909384\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=0.6s - 0.7s, acc=0.911967\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=0.7s - 0.8s, acc=0.905295\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=0.8s - 0.9s, acc=0.905080\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=0.9s - 1.0s, acc=0.911537\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=1.0s - 1.1s, acc=0.907447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4646, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=1.1s - 1.2s, acc=0.912613\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=1.2s - 1.3s, acc=0.910891\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=1.3s - 1.4s, acc=0.910030\n",
      "2024-06-18 03:48 INFO loaded_weight=['2024-06-14_SCNN18_Sigmoid_RWC_training_4_C0.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C1.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C2.h5', '2024-06-14_SCNN18_Sigmoid_RWC_training_4_C3.h5', '2024-06-15_SCNN18_Sigmoid_RWC_training_4_C4.h5'], test_dataset=SCNNR-RWC-test_4.h5, second_range=1.4s - 1.5s, acc=0.907232\n"
     ]
    }
   ],
   "source": [
    "# 使用 N 個分類器進行平均數後以 0.5 做閾值\n",
    "predictions = [model.predict(test_data) for model in models]\n",
    "predictions = np.array(predictions)\n",
    "avg_predictions = np.mean(predictions, axis=0)\n",
    "print(avg_predictions.shape)\n",
    "\n",
    "for i in range(nb_classes):\n",
    "    predict_true = 0\n",
    "\n",
    "    for index, result in enumerate(avg_predictions):\n",
    "        if result[i] < 0.5 and test_label[index][i] == 0:\n",
    "            predict_true += 1\n",
    "        elif result[i] >= 0.5 and test_label[index][i] == 1:\n",
    "            predict_true += 1\n",
    "\n",
    "    acc = predict_true/avg_predictions.shape[0]\n",
    "\n",
    "    LOG.info(f'loaded_weight={training_weights}, test_dataset={test_dataset}, second_range={test_label_range[i]}, acc={acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.predict(test_data)\n",
    "# print(results.shape)\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     threshold = i * 0.1\n",
    "#     accs = []\n",
    "#     for j in range(nb_classes):\n",
    "#         predict_true = 0\n",
    "\n",
    "#         for index, result in enumerate(results):\n",
    "#             if result[j] < threshold and test_label[index][j] == 0:\n",
    "#                 predict_true += 1\n",
    "#             elif result[j] >= threshold and test_label[index][j] == 1:\n",
    "#                 predict_true += 1\n",
    "\n",
    "#         acc = predict_true/results.shape[0]\n",
    "#         accs.append(acc)\n",
    "\n",
    "#     LOG.info(f'threshold = {threshold:.1f}, loaded_weight={training_weight}, test_dataset={test_dataset}, acc={np.round(np.mean(accs)*100, 4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex output using softmax\n",
    "\n",
    "# predictions = model.predict(test_data)\n",
    "# results = np.square(predictions[0]) + np.square(predictions[1])\n",
    "\n",
    "# predict_true = 0\n",
    "# data_size = results.shape[0]\n",
    "# print(data_size)\n",
    "\n",
    "# for index, result in enumerate(results):\n",
    "#     if result[0] > result[1] and test_label[index][1] == 0:\n",
    "#         predict_true += 1\n",
    "#     elif result[1] > result[0] and test_label[index][1] == 1:\n",
    "#         predict_true += 1\n",
    "#     elif result[1] == result[0]:\n",
    "#         data_size -= 1\n",
    "\n",
    "# acc = predict_true/data_size\n",
    "\n",
    "# LOG.info(f'loaded_weight={training_weight}, test_dataset={test_dataset}, acc={acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determinate threshold for complex sigmoid\n",
    "\n",
    "# test_data_for_threshold = test_data[:int(len(test_data)/10)]\n",
    "# test_label_for_threshold = test_label[:int(len(test_label)/10)]\n",
    "\n",
    "# predictions = model.predict(test_data_for_threshold)\n",
    "# results = np.sqrt(np.square(predictions[0]) + np.square(predictions[1]))\n",
    "\n",
    "# accs = []\n",
    "# data_size = results.shape[0]\n",
    "# print(data_size)\n",
    "\n",
    "# for i in range(0, int(np.sqrt(2)*1000)):\n",
    "#     predict_true = 0\n",
    "#     t = i / 1000\n",
    "#     for index, result in enumerate(results):\n",
    "#         if result <= t and test_label_for_threshold[index] == 0:\n",
    "#             predict_true += 1\n",
    "#         elif result > t and test_label_for_threshold[index] == 1:\n",
    "#             predict_true += 1\n",
    "\n",
    "#     acc = predict_true/data_size\n",
    "#     accs.append(acc)\n",
    "\n",
    "# threshold = np.argmax(np.array(accs))/1000\n",
    "# predictions = model.predict(test_data)\n",
    "# results = np.sqrt(np.square(predictions[0]) + np.square(predictions[1]))\n",
    "# predict_true = 0\n",
    "# data_size = results.shape[0]\n",
    "# print(data_size)\n",
    "\n",
    "# for index, result in enumerate(results):\n",
    "#     if result <= threshold and test_label[index] == 0:\n",
    "#         predict_true += 1\n",
    "#     elif result > threshold and test_label[index] == 1:\n",
    "#         predict_true += 1\n",
    "\n",
    "# acc = predict_true/data_size\n",
    "\n",
    "# LOG.info(f'loaded_weight={training_weight}, test_dataset={test_dataset}, acc={acc:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
